# Ollama Configuration
OLLAMA_MODEL=deepseek-r1:7b-qwen-distill-q8_0
OLLAMA_URL=http://localhost:11434
OLLAMA_TIMEOUT_MINUTES=2

# Chat Settings
CHAT_TEMPERATURE=0.7
CHAT_TOP_P=0.9
CHAT_SYSTEM_PROMPT=You are a helpful and friendly AI assistant. You maintain context from our conversation and provide thoughtful, relevant responses.